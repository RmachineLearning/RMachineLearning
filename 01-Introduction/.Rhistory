library(ggplot2)
ggplot(tophit,  aes(x=avg,  y=reorder(name,  avg))) +
geom_point(size=3) + # Use a larger dot
theme_bw() +
theme(panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.y = element_line(colour="grey60" ,  linetype="dashed" ))
install.packages("gcookbook")
tophit = tophitters2001[1:25, ]
library(gcookbook)
tophit = tophitters2001[1:25, ]
ggplot(tophit,  aes(x=avg,  y=reorder(name,  avg))) +
geom_point(size=3) + # Use a larger dot
theme_bw() +
theme(panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.y = element_line(colour="grey60" ,  linetype="dashed" ))
ggplot(tophit,  aes(x=avg,  y=reorder(name,  avg))) +
geom_point(size=3)
ggplot(tophit,  aes(x=avg,  y=reorder(name,  avg))) +
geom_point(size=3)
ggplot(tophit,  aes(x=avg,  y=reorder(name,  avg))) +
geom_point(size=3) + # Use a larger dot
theme_bw()
ggplot(tophit,  aes(x=avg,  y=reorder(name,  avg))) +
geom_point(size=3) + # Use a larger dot
theme_bw() +
theme(panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.y = element_line(colour="grey60" ,  linetype="dashed" ))
ggplot(tophit,  aes(x=avg,  y=reorder(name,  avg))) +
geom_point(size=3) + # Use a larger dot
theme_bw() +
theme(panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank())
library(plyr)
tg <-  ddply(ToothGrowth,  c("supp" , "dose" ),  summarise,  length=mean(len))
tg
ToothGrowth
library(maptools)
China <- readShapePoly("E:\\workspace\\R\\画图\\地理画图\\全国地理文件\\中国地理总文件\\CHN_adm1.shp")
vent.map <-readShapeSpatial("E:\\workspace\\R\\画图\\地理画图\\全国地理文件\\中国地理总文件\\CHN_adm1.shp")
vent.map
install.packages("ff")
v = ff(vmode = "double", length = 1e+08)
library(ff)
v = ff(vmode = "double", length = 1e+08)
filename(v)
setwd("E:/workspace/R")
object.size(v)
file.info(filename(v) )$size
library(RCurl)
temp <- getURL("http://www.dataguru.cn/",debugfunction=d$update,verbose =TRUE)
d = debugGatherer()
temp <- getURL("http://www.dataguru.cn/",debugfunction=d$update,verbose =TRUE)
cat(d$value()[3])
cat(d$value()[1])
cat(d$value()[2])
headers = basicTextGatherer()
txt=getURL("http://www.dataguru.cn/",headerfunction = headers$update)
names(headers$value())#说明是字符串形式
headers$value()
h = basicHeaderGatherer()
txtt=getURL("http://www.dataguru.cn/",headerfunction = h$update)
names(h$value())
names(headers$value())
h$value()
curl = getCurlHandle()
d=getURL("http://www.dataguru.cn/", curl = curl)
getCurlInfo(curl)$response.code
getCurlInfo(curl)
url = getURL("http://rfunction.com/code/1202/")
temp<- getBinaryURL(url)
wp = getURL("http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus")
doc <- htmlParse(wp, asText = TRUE)
library(XML)
doc <- htmlParse(wp, asText = TRUE)
tables <- readHTMLTable(doc)
tables
head(tables)
str(tables)
tables$table1
head(tables$table1
)
head(tables$table1)
dizhen = getURL("http://data.earthquake.cn/datashare/datashare_more_quickdata_new.jsp")
dizhen_data <- getURL(dizhen)
doc <-htmlParse(wp, asText = TRUE)
tables <- readHTMLTable(doc,header=F)
head(tables)
head(tables$table1)
dizhen_doc <-htmlParse(dizhen, asText = TRUE)
dizhen_tables <- readHTMLTable(dizhen_doc,header=F)
head(dizhen_tables)
install.packages("RExcelInstaller", "rcom", "rsproxy")
require(devtools)
install.packages(devtools)
install.packages(“httr”)
install.packages("httr")
install.packages("devtools")
install_github("ramnathv/rCharts")
install_github("rcharts/ramnathv")
require(devtools)
find_rtools()
install.packages(c("abind", "adabag", "AER", "amap", "arules", "bayesm", "bdsmatrix", "BH", "boot", "bootstrap", "BradleyTerry2", "BRugs", "cairoDevice", "car", "caret", "caTools", "chron", "class", "classInt", "cluster", "coda", "colorspace", "corpcor", "corrgram", "coxme", "DCluster", "deldir", "DEoptimR", "deSolve", "diagram", "digest", "doBy", "dplyr", "dse", "e1071", "Ecdat", "Ecfun", "effects", "emplik", "evaluate", "fBasics", "fda", "fields", "forecast", "foreign", "formatR", "Formula", "gam", "gdata", "gee", "geoR", "geosphere", "GGally", "ggm", "ggmap", "ggplot2", "glmnet", "goftest", "GPArotation", "gplots", "gss", "gstat", "gtools", "gWidgetsRGtk2", "HH", "highr", "Hmisc", "htmltools", "httpuv", "igraph", "intervals", "ipred", "JM", "JMbayes", "kernlab", "KernSmooth", "kknn", "knitr", "kohonen", "labeling", "lava", "lme4", "lmtest", "manipulate", "mapdata", "mapproj", "maps", "maptools", "markdown", "MASS", "Matrix", "mboost", "mfp", "mime", "minqa", "mnormt", "MSBVAR", "multcomp", "mutoss", "mvoutlier", "nlme", "NLP", "nnet", "numDeriv", "party", "pcaPP", "pgirmess", "plotrix", "plspm", "plyr", "polyclip", "prodlim", "pscl", "psych", "pwr", "quantmod", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "R2WinBUGS", "R6", "RandomFields", "randomForest", "RANN", "raster", "Rcmdr", "RColorBrewer", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "reshape2", "rgdal", "rgeos", "rgl", "RgoogleMaps", "rjson", "rmarkdown", "rminer", "robCompositions", "robustbase", "ROCR", "RODBC", "rpart", "rpart.plot", "rrcov", "sandwich", "scales", "sem", "seriation", "setRNG", "shape", "shiny", "sp", "spacetime", "spam", "SparseM", "spatial", "spatstat", "spBayes", "spdep", "sphet", "splancs", "splm", "stabledist", "statmod", "stringr", "strucchange", "survival", "systemfit", "tcltk2", "tfplot", "tframe", "TH.data", "timeDate", "timeSeries", "tm", "tsDyn", "tseries", "TSP", "TTR", "vcd", "VIM", "xlsxjars", "XML", "xtable", "zoo"))
install.packages(c("abind", "adabag", "AER", "amap", "arules",
install.packages(c("abind", "adabag", "AER", "amap", "arules", "bayesm", "bdsmatrix", "BH", "boot", "bootstrap", "BradleyTerry2", "BRugs", "cairoDevice", "car", "caret", "caTools", "chron", "class", "classInt", "cluster", "coda", "colorspace", "corpcor", "corrgram", "coxme", "DCluster", "deldir", "DEoptimR", "deSolve", "diagram", "digest", "doBy", "dplyr", "dse", "e1071", "Ecdat", "Ecfun", "effects", "emplik", "evaluate", "fBasics", "fda", "fields", "forecast", "foreign", "formatR", "Formula", "gam", "gdata", "gee", "geoR", "geosphere", "GGally", "ggm", "ggmap", "ggplot2", "glmnet", "goftest", "GPArotation", "gplots", "gss", "gstat", "gtools", "gWidgetsRGtk2", "HH", "highr", "Hmisc", "htmltools", "httpuv", "igraph", "intervals", "ipred", "JM", "JMbayes", "kernlab", "KernSmooth", "kknn", "knitr", "kohonen", "labeling", "lava", "lme4", "lmtest", "manipulate", "mapdata", "mapproj", "maps", "maptools", "markdown", "MASS", "Matrix", "mboost", "mfp", "mime", "minqa", "mnormt", "MSBVAR", "multcomp", "mutoss", "mvoutlier", "nlme", "NLP", "nnet", "numDeriv", "party", "pcaPP", "pgirmess", "plotrix", "plspm", "plyr", "polyclip", "prodlim", "pscl", "psych", "pwr", "quantmod", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "R2WinBUGS", "R6", "RandomFields", "randomForest", "RANN", "raster", "Rcmdr", "RColorBrewer", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "reshape2", "rgdal", "rgeos", "rgl", "RgoogleMaps", "rjson", "rmarkdown", "rminer", "robCompositions", "robustbase", "ROCR", "RODBC", "rpart", "rpart.plot", "rrcov", "sandwich", "scales", "sem", "seriation", "setRNG", "shape", "shiny", "sp", "spacetime", "spam", "SparseM", "spatial", "spatstat", "spBayes", "spdep", "sphet", "splancs", "splm", "stabledist", "statmod", "stringr", "strucchange", "survival", "systemfit", "tcltk2", "tfplot", "tframe", "TH.data", "timeDate", "timeSeries", "tm", "tsDyn", "tseries", "TSP", "TTR", "vcd", "VIM", "xlsxjars", "XML", "xtable", "zoo"))
install.packages(c("abind", "adabag", "AER", "amap", "arules",
library("abind", lib.loc="E:/Program Files/R/R-3.2.1/library")
install.packages("dse")
install.packages("GPArotation")
install.packages(c("timeDate", "timeSeries", "tseries"))
library("dplyr", lib.loc="E:/Program Files/R/R-3.2.1/library")
lbrary(dplyr)
library(dplyr)
library("plyr", lib.loc="E:/Program Files/R/R-3.2.1/library")
xx<- array(1:24,c(3,4,2))
a<-array(1:21,c(3,7))
require(plyr)
library(plyr)
aaply(.data=a, .margins=1, .fun=mean)
a
xx
aaply(.data=a,  2, mean,  process="text")
names=c("john","mary","Alice","Peter","ROger","Phyillis")
age=c(13,15,14,13,14,13)
sex=c("M","F","F","M","M","F")
data=data.frame(names,age,sex)
aaply(.data=xx, .margins=1, .fun=mean)
aaply(.data=xx,  .margins = 2, .fun=mean,  process="text")
amean=function(data)
{
agemean=mean(data[,2])
return(agemean)
}
daply(data,.(sex,age),amean)
data
.parseISO8601('2000')
library(xts)
.parseISO8601('2000')
x <- timeBasedSeq('2010-01-01/2010-01-02 12:00')
x <- xts(1:length(x), x)
head(x)
indexClass(x)
indexFormat(x) <- "%Y-%b-%d %H:%M:%OS3"
head(x)
indexFormat(x) <- "%Y-%b-%d %H:%M:%OS3"
head(x)
x <- Sys.time() + 1:30
x
data(sample_matrix)
to.period(sample_matrix)
class(to.period(sample_matrix))
samplexts <- as.xts(sample_matrix)
to.period(samplexts)
class(to.period(samplexts))
endpoints(sample_matrix)
endpoints(sample_matrix, 'days',k=7)
endpoints(sample_matrix, 'weeks')
endpoints(sample_matrix, 'months')
(x <- xts(4:10, Sys.Date()+4:10))
(y <- xts(1:6, Sys.Date()+1:6))
merge(x,y)
merge(x,y, join='inner')
merge(x,y, join='left')
data(sample_matrix)
x <- as.xts(sample_matrix)
x
split(x)[[1]]
split(x)[[2]]
x <- xts(1:10, Sys.Date()+1:10)
x[c(1,2,5,9,10)] <- NA
x
na.locf(x)
na.locf(x, fromLast=TRUE)
xts.ts <- xts(rnorm(231),as.Date(13514:13744,origin="1970-01-01"))
start(xts.ts)
end(xts.ts)
zoo.data <- zoo(rnorm(31)+10,as.Date(13514:13744,origin="1970-01-01"))
ep <- endpoints(zoo.data,'weeks')
ep
timeBased(Sys.time())
timeBased(Sys.Date())
timeBased(200701)
timeBasedSeq('20080101 0830',length=100)
x <- xts(1:5, Sys.Date()+1:5)
x
lag(x)
library(RCurl)
headers = basicTextGatherer()
txt=getURL("http://www.dataguru.cn/",headerfunction = headers$update)
headers$value()
h = basicHeaderGatherer()
txtt=getURL("http://www.dataguru.cn/",headerfunction = h$update)
names(h$value())
h$value()
myheader <- c(
"User-Agent"="Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1.6) ",
"Accept"="text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
"Accept-Language"="en-us",
"Connection"="keep-alive",
"Accept-Charset"="GB2312,utf-8;q=0.7,*;q=0.7"
)
d = debugGatherer()
d$value()
temp <- getURL("http://www.dataguru.cn/",
httpheader = myheader,
debugfunction=d$update,verbose =TRUE)
cat(d$value()[3])#提交给服务器的头信息
temp <- getURL("http://www.dataguru.cn/",debugfunction=d$update,verbose =TRUE)
cat(d$value()[3])#提交给服务器的头信息
url.exists("http://cos.name/bbs/login.php?")
curl = getCurlHandle()
d=getURL("http://cos.name/cn/topic/411708/", curl = curl)
getCurlInfo(curl)$response.code
getCurlInfo(curl)
h = basicHeaderGatherer()
txtt=getURL("http://cos.name/cn/topic/411708/",headerfunction = h$update)
names(h$value())
h$value()
d$value()
getCurlInfo(curl)
headers = basicTextGatherer()
txt=getURL("http://www.dataguru.cn/",headerfunction = headers$update)
names(headers$value())#说明是字符串形式
headers$value()
wangye = "https://www.baidu.com/s?word=%E6%95%B0%E6%8D%AE%E7%82%BC%E9%87%91&tn=sitehao123&ie=utf-8&ssl_sample=hao_1"
getForm(wangye)
getFormParams(wangye)
wangye = "https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=1&tn=sitehao123&wd=RCurl&rsv_pq=da9cc0e900002b3e&rsv_t=259epf8EriexZ%2BBZqNgP0OLqTB6cvNAoPESiSn3z8LSnmaQ2jHMfVD76sLy%2F9v03Jg&rsv_enter=1&rsv_sug3=13&rsv_sug1=13&rsv_sug2=0&inputT=7148&rsv_sug4=7149"
getFormParams(wangye)
setwd("E:/workspace/R/machine learning/01-Introduction")
library(ggplot2)    # We'll use ggplot2 for all of our visualizations
library(plyr)       # For data manipulation
library(scales)
names(ufo) <- c("DateOccurred", "DateReported",
"Location", "ShortDescription",
"Duration", "LongDescription")
#na.strings = '' 将空元素设置为NA
ufo <- read.delim(file.path("data", "ufo", "ufo_awesome.tsv"),
sep = "\t",
stringsAsFactors = FALSE,
header = FALSE,
na.strings = "")
head(ufo)
names(ufo) <- c("DateOccurred", "DateReported",
"Location", "ShortDescription",
"Duration", "LongDescription")
head(ufo)
ufo$DateOccurred <- as.Date(ufo$DateOccurred, format = "%y%m%d")
good.rows <- ifelse(nchar(ufo$DateOccurred) != 8 |
nchar(ufo$DateReported) != 8,
FALSE,
TRUE)
length(which(!good.rows))      # While 731 rows may seem like a lot, out of over 60K
ufo <- ufo[good.rows, ]        # it is only about 0.6% of the total number of records.
length(good.rows)
ufo$DateOccurred <- as.Date(ufo$DateOccurred, format = "%Y%m%d")
ufo$DateReported <- as.Date(ufo$DateReported, format = "%Y%m%d")
get.location <- function(l)
{
#1 首先用异常处理函数tryCath()包围strsplit()函数
#当strsplit函数遇到不符合格式的数据会抛出异常(例如该字符串中没有逗号)
#因此要捕捉(catch)这个异常,不包含逗号的数据，返回一个NA向量来表示这条数据无效
split.location <- tryCatch(strsplit(l, ",")[[1]],
error = function(e) return(c(NA, NA)))
#2 其次，用正则表达式函数gsub()移除每个字符串开头的一个空格(^后面有一个空格)
clean.location <- gsub("^ ","",split.location)
#3 许多非美国地名中会返回多个逗号，导致strsplit函数返回向量长度大于2
#此时依然返回NA向量
if (length(clean.location) > 2)
{
return(c(NA,NA))
}
else
{
return(clean.location)
}
}
city.state <- lapply(ufo$Location, get.location)
head(city.state)
location.matrix <- do.call(rbind, city.state)
#由于州名缩写不一致，所以在这里用tolower把所有州名字缩写改为小写
ufo <- transform(ufo,
USCity = location.matrix[, 1],
USState = tolower(location.matrix[, 2]),
stringsAsFactors = FALSE)
ufo$USState <- state.abb[match(ufo$USState, state.abb)]
names(ufo)
head(state.abb)
str(state.abb)
ufo.us <- subset(ufo, !is.na(USState))
head(ufo.us)
ufo$USState <- state.abb[match(ufo$USState, state.abb)]
ufo.us <- subset(ufo, !is.na(USState))
summary(ufo.us)
head(ufo.us)
head(ufo)
ufo$USState <- state.abb[match(ufo$USState, state.abb)]
head(ufo)
(state.abb)
get.location <- function(l)
{
#1 首先用异常处理函数tryCath()包围strsplit()函数
#当strsplit函数遇到不符合格式的数据会抛出异常(例如该字符串中没有逗号)
#因此要捕捉(catch)这个异常,不包含逗号的数据，返回一个NA向量来表示这条数据无效
split.location <- tryCatch(strsplit(l, ",")[[1]],
error = function(e) return(c(NA, NA)))
#2 其次，用正则表达式函数gsub()移除每个字符串开头的一个空格(^后面有一个空格)
clean.location <- gsub("^ ","",split.location)
#3 许多非美国地名中会返回多个逗号，导致strsplit函数返回向量长度大于2
#此时依然返回NA向量
if (length(clean.location) > 2)
{
return(c(NA,NA))
}
else
{
return(clean.location)
}
}
# We use 'lapply' to return a list with [City, State] vector as each element
#lapply返回一个list链表,因为每条字符串被分隔成为了两个字符串，所以用链表存储最好
#list是一个“键-值”对形式的数据结构，键由双方括号索引，值在单方括号中
city.state <- lapply(ufo$Location, get.location)
head(city.state)
location.matrix <- do.call(rbind, city.state)
#由于州名缩写不一致，所以在这里用tolower把所有州名字缩写改为小写
ufo <- transform(ufo,
USCity = location.matrix[, 1],
USState = tolower(location.matrix[, 2]),
stringsAsFactors = FALSE)
head(ufo)
ufo$USState <- state.abb[match(ufo$USState, state.abb)]
ufo.us <- subset(ufo, !is.na(USState))
head(ufo.us)
head(ufo)
ufo <- transform(ufo,
USCity = location.matrix[, 1],
USState = toupper(location.matrix[, 2]),
stringsAsFactors = FALSE)
ufo$USState <- state.abb[match(ufo$USState, state.abb)]
head(ufo)
ufo.us <- subset(ufo, !is.na(USState))
head(ufo.us)
summary(ufo.us)
quick.hist <- ggplot(ufo.us, aes(x = DateOccurred)) +
geom_histogram() +
scale_x_date(breaks = "50 years")
print(quick.hist)
ufo.us <- subset(ufo.us, DateOccurred >= as.Date("1990-01-01"))
nrow(ufo.us)
new.hist <- ggplot(ufo.us, aes(x = DateOccurred)) +
geom_histogram(aes(fill='white', color='red')) +
scale_fill_manual(values=c('white'='white'), guide="none") +
scale_color_manual(values=c('red'='red'), guide="none") +
scale_x_date(breaks = "50 years")
print(new.hist)
ufo.us$YearMonth <- strftime(ufo.us$DateOccurred, format = "%Y-%m")
sightings.counts <- ddply(ufo.us, .(USState,YearMonth), nrow)
sightings.counts
head(sightings.counts)
date.range <- seq.Date(from = as.Date(min(ufo.us$DateOccurred)),
to = as.Date(max(ufo.us$DateOccurred)),
by = "month")
date.strings <- strftime(date.range, "%Y-%m")
date.range <- seq.Date(from = as.Date(min(ufo.us$DateOccurred)),
to = as.Date(max(ufo.us$DateOccurred)),
by = "month")
date.strings <- strftime(date.range, "%Y-%m")
states.dates <- lapply(state.abb, function(s) cbind(s, date.strings))
states.dates <- data.frame(do.call(rbind, states.dates),
stringsAsFactors = FALSE)
all.sightings <- merge(states.dates,
sightings.counts,
by.x = c("s", "date.strings"),
by.y = c("USState", "YearMonth"),
all = TRUE)
head(all.sightings)
names(all.sightings) <- c("State", "YearMonth", "Sightings")
all.sightings$Sightings[is.na(all.sightings$Sightings)] <- 0
all.sightings$YearMonth <- as.Date(rep(date.range, length(state.abb)))
all.sightings$YearMonth <- as.Date(rep(date.range, length(state.abb)))
#创建一个图层，x轴为x = YearMonth, y轴为y = Sightings
state.plot <- ggplot(all.sightings, aes(x = YearMonth,y = Sightings)) +
#为了表现各州的周期性变化，给每一个州绘制一副曲线图，可以方便我们观察每个州
#UFO目击次数随着时间的变化的峰值 低谷 波动区， 线条颜色dakblue深蓝色
geom_line(aes(color = "darkblue")) +
#创建分块绘制图形，并指明图形面板的构造使用State变量，它是一个factor类型分类变量
#并定义网格的行数和列数
facet_wrap(~State, nrow = 10, ncol = 5) +
#默认的是绘制主题是灰色背景，深灰色网格线，
#为了更容易看清楚数据之间不同之处，这里添加theme_bw()层，该图层为白色背景，黑色网格线
theme_bw() +
#用来指明字符串"darkblue"相当于网页安全色"darkblue"，
#ggplot2倾向用颜色区分分类变量，即用factor类型指明颜色
#我们明确将颜色定义成一个字符串类型，因此还要用scale_color_manual函数定义这个字符串的值
scale_color_manual(values = c("darkblue" = "darkblue"), guide = "none") +
#用来指明可视化结果中主要网格线，因为这份数据的跨度为20年，所以我们间隔设置为5年
scale_x_date(breaks = "5 years", labels = date_format('%Y')) +
xlab("Years") +
ylab("Number of Sightings") +
#用ggtitle赋一个主题
ggtitle("Number of UFO sightings by Month-Year and U.S. State (1990-2010)")
print(state.plot)
